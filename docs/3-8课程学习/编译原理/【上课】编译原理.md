# 编译原理

## 基本信息

上课的教材是虎书龙书。覆盖的虎书内容章节是：1~11,13,14,18。

- 成绩构成  
10% 作业  
10% 小测  
15% 期中考试  
25% 项目 DDL:5.28  
40% 期末作业

## 2-27 第一周

### 1.1 Modules and Interfaces

编译过程可以被划分为多个阶段，如词法分析器，语法分析器之类。分成模块之后，模块可以做到复用，避免了重复造轮子等问题。

### 1.2 Tools and Software

正则表达式：词法分析  
上下文无关文法：语法分析

Lex：Lex 工具可以根据用户提供的声明式规范，生成对应的词法分析器代码。
Yac：可以生成语法分析器代码。

### 1.3 Data Structure

我们采用树形结构来表示 IR。

![](img/dcd866109b937aeb58b60f4ee0cd9319_MD5.png)

我们通过结构体来表达在 grammar 处于 left hand 的变量。这种结构体由两种成员变量组成。第一种类型是 kind，他是一种 enum 类型，代表了当前结构体具体的类型。例如一个 A_stm_ 类型的机构体，其可能是 CompoundStm, 也可能是 AssignStm。第二种类型是 u, 它是一种 union 类型，用来存储具体的数据。

![](img/6e1ad82ea8e779324fa5d27b54570452_MD5.png)

由于分配空间的需要，因此我们在程序中通常采用的是指向结构体的指针。

### 2.1 Lexical Tokens

lexical token，词法单元。词法分析器，输入的是字符串流，输出的是词法单元流。词法单元流中的每一个词法单元必须符合特定的形式。

为了方便构造一个词法分析器，我们通常采用将我们想要的 lexical tokens 表示为 regular expression 的形式，而后通过 NFA 和 DFA，最终转换成我们想要的 lexer。

### 2.2 Regular Expression

`“”` 用引号表示必须要完全相同才能进行匹配。
`[a-z]` 代表可以匹配 a-z 中任意一个。
`[a-zA-Z]` 代表可以匹配 a-z, A-Z 中任意一个。
`.` 可以匹配任何  
`+` 匹配 `+` 前边的内容一次或多次  
`?` 匹配 `?` 前边的内容零次或一次

两个匹配的规则：

- Longest match: 最长匹配规则是指从输入中可以匹配任何正则表达式的最长初始子串作为下一个 token。这意味着，在使用最长匹配规则时，程序会尝试将输入中最长的子串与正则表达式匹配，直到找到一个匹配为止。
- Rule priority: 规则优先级是指在特定的最长初始子串中，可以匹配的第一个正则表达式决定了它的 token 类型。这意味着，当程序找到一个最长子串时，它将首先尝试使用第一个正则表达式进行匹配，如果成功，它将将该子串标记为该正则表达式所代表的 token 类型。

### 2.3 Finite Automata

为了跟踪最长匹配规则，我们可以使用两个变量：Last-Final（最近遇到的终止状态的状态号）和 Input-Position-at-Last-Final（最近遇到的终止状态的输入位置）。每当进入一个终止状态时，词法分析器都会更新这些变量。

Last-Final 记录最近遇到的终止状态的状态号，即已经成功匹配了某个正则表达式的子串所在的状态。这个变量的更新可以在进入每个终止状态时进行。如果在接下来的匹配中发现更长的子串可以匹配其他正则表达式，则更新 Last-Final 的值。

Input-Position-at-Last-Final 记录了最近遇到的终止状态的输入位置。这个变量在 Last-Final 更新时也应该一同更新。因为在更新 Last-Final 之后，我们需要将当前输入位置设置为 Input-Position-at-Last-Final，以便继续匹配后面的子串。

使用这两个变量，我们可以跟踪最长匹配规则，并在遇到终止状态时更新匹配位置。这种方法可以在词法分析中实现最长匹配规则，提高程序的效率和准确性。

deadstate：如果词法分析器到达一个无输出转移的非终止状态，这个状态就被称为“死状态”。此时，我们需要使用变量来记录已匹配的 token 以及其结束位置。

### 2.4 Nondeterministic Finite Automata

主要注意的是将 NFA 转换为 DFA 的过程。

## 3-6 第二周

### 3.1 Context Free Grammar

解析器需要根据语法规则来判断一个输入的 token 流是否符合特定的语法规则。这里我们使用的语法规则就是 CFG。当然 CFG 并不能表示所有的语言，但是对于编程语言而言，采用 CFG 是完全够用了的。

- derivation

derivation 描述的是如何从一个 start symbol $S$ 最终演化成我们最后的 language。我们可以将 derivation 的过程用树表示，这个树就是一个 parse tree。如果一个 string 可以被表示为多个不同的 parse tree，我们认为这个 grammar 是存在 ambiguity 问题的，因此我们需要重写 grammar 以使其不再 ambiguous。

### 3.2 Predictive Parsing

parsing 可以分为两种大的方式，一种是 top-down parsing，另一种是 bottom-up parsing。在这个编译原理课中，我们着重讲了 top-down parsing 中的 predictive parsing，也即 ll(k) parsing。这里的 ll(k) 指的是, parsing from left to right，left most derivation，look ahead k tokens。

为了使用 predictive parsing，我们通常的做法是将每个非终结符的 nullable，FIRST，FOLLOW 给表示出来。通常的做法是不断遍历每个 derivation，直到与前一次相比，nullable,FIRST 和 FOLLOW 都没有变化。最终结果可以通过表格来清晰表示。

一但表示出来这三个后，我们可以绘制第二张表格，在这个表格中，行代表了每个非终结符，列代表了 look ahead 得到的 token，而表格中的内容则代表了可以采取的 derivation。如果在一个格子中出现了两个 derivation，我们认为这时候需要改写 grammar。

## 3-13 第三周

这周主要讲了 LR parsing，这种做法是自底向上的一种方法。

LR(0) 分析是一种自底向上的语法分析技术。具体来说，该技术的步骤如下：首先根据文法构建出对应的 NFA（也可以省略，直接构造对应的 DFA），然后创建出对应的 DFA。接着，根据 DFA，构建出语法分析表（parsing table），在 NFA 每一个状态下，读入不同的终结符或非终结符时，对应的 DFA 会进行相应的移进或规约操作，这些操作的规则被编码到语法分析表中。最后，利用该表进行语法分析，解析输入的字符串。需要注意的是，LR(0) 分析器可以处理大部分上下文无关文法，但是在处理某些文法时可能会出现移进 - 规约冲突或规约 - 规约冲突，需要使用其他的 LR 分析器进行处理。

## 3-20 第四周

首先讲了 slr。

SLR 是 simple LR parsing 的缩写，相较于 LR（0）而言，它在构建 parsing table 时，只有在当前产生式左部的 follow 集合中存在当前字符时，才会将 reduce 动作填入 parsing table。而在 LR（0）中，如果存在 reduce 动作，则会将其填入该行中的每个字符对应的 entry 中。

接下来介绍了 LR(1) 算法。

引入 LR(1) 是因为在 SLR 中仍然存在冲突的情况。使用 LR(1) 可以在特定的上下文环境中查看一种 reduce 是否可能。在 LR(1) 中，每个状态都包含了一个 lookahead 符号，使得它能够区分在不同上下文中出现的相同前缀。这样，LR(1) 能够更精确地处理语法规则，避免了 SLR 中出现的一些冲突。

而后又介绍了 LALR(1) parsing。

LALR(1) 是一种语法分析算法，它是在 LR(1) 算法的基础上进行了状态合并。在 LALR(1) 中，将 LR(1) 中具有相同核心但 lookahead 符号不同的状态进行合并，形成新的状态。这种状态合并的方式可以减少 LR(1) 的状态数，从而减小 parsing table 的大小。因此，LALR(1) 比 LR(1) 更具有实用性和可行性。

也讲了从语法错误中进行恢复，使得语法分析可以从一次的分析中得出所有的错误内容。Local error recovery 没法向后看，而 global error recovery 相对而言更加强大。

## 3-27 第五周

介绍了 Global error recovery 的一种算法：Burke-FIsher Error Repaire。

Bureke-Fisher Error Repaire 会检查之前的 K 个 token，尝试每一种 sigle-token 的插入，删除，替换策略，直到可以恢复错误。为了确保这种修改确定足够好，我们应该要使得这样修改后，parser 可以接着读一些 tokens。为了实现这样的 buieke-fisher 策略，我们的 parser 不仅仅需要记录 k 个已经读过的 token，并且要记录读 k 个 token 之前的状态。即 parser 需要维护：当前状态 stack，k 个 token 之前的状态 stack，以及这 k 个 token。Bureke-Fisher 还有的一个好处是完全不需要修改语法。semantic action 只在 old stack 上执行。程序员可以先启发给这个 parser 一些明显的错误，和其修复方式。tiger 语言中用 let…in…end 表示作用域，因此 parser 有时候会尝试插入 in int end 这样来强制关闭只写了 let 的情况。

之后进入了 abstract syntax 这一大章节，首先介绍了 semantic actions，语义动作。

abstract syntax 是语法和语义的接口。在一个 recursive-descent parser 中，semantic actions 就是 parsing function 返回的语义值，或者是这个 parsing function 的 side effect。

yacc 也会自动生成语义动作。利用 $i, \$\$ 等符号。yacc 中含有语义值栈和 symbol 栈（parse 栈），每当执行规约操作的时候，就会执行对应的语义动作。

这里在学习的过程中，突然不明白最左推导和最右推导的区别。最左推导和最右推导指的是由 S 生成 最后的 string 的时候，优先对哪一个非终结符进行转换。LR 之所以是最右推导的，是因为 reduction 优先对刚刚 push 到栈中的 symbol 进行 reduction，因为它刚进入，所以是最右的。也即如果我们要对 S -> A B 中的 A 语义值的话，那么 B 肯定是准备好了的。

接下来介绍了 Abstract parse tree

Abstract parse tree 的出现是因为，将 sematic action 直接在 systax analysis 中执行一种难以阅读的方法。一个 concrete parse tree 会有很多冗余的信息，并且和语法深度绑定，但实际上，语义分析的时候只要语义没变，语义分析的输入不应该发生变化。于是我们出现了 abstract parse tree。

我们可以利用 abstract syntax 构建出 abstract syntax tree。在 C 语言中，可以构造一个结构体，结构体中第一个字段表明了这个 nun-terminal 的类型，结构体中第二个字段表明了这个 nunterminal 的具体数值。compiler 完成这一步不是通过人手动的构造，而是通过 sematic action 构建 ast。为了便于报错，abstract syntax tree 的每一个节点都需要保留有 position 信息。

接下来将了 semantic analysis 语义分析

语义分析完成了以下的功能：1 将变量的定义与其使用相连接 2 检查每个表达式的类型是否正确 3 将抽象语法转化为更简单的表示形式，方便生成 machine code。sematic analysis 需要维护一个 symbol table（也被称为 environments）。symbol table 是一个 table，key 是 indentifier，value 是对应的值/类型。这个 table 会随着作用域 scope 变化。

symbol table 需要支持查找，插入，恢复。实现 symbol table 有两种方式，一种是函数式方式，一种是命令式方式。函数式方式会创建新的 symbol table，保持原有的 symbol table 不变，因此是易于恢复的。命令式会将 $\sigma_{1}$ 修改为 $\sigma_{2}$，如果我们想要回到原先状态，那么需要 undo 前面的操作。

介绍了如何使用 sematic 和

用命令式方法实现 symbol table。维护 symbol table 通畅使用 hash 表，每个 entry 对应一个链表，新进入的是链表头。如何用函数式方法实现 symbol table。如果直接修改，不符合函数式方法的哲学。如果复制一份，代价过高不好承受。常用的做法是使用一个 binary search tree。

## 4-3 第六周

开始介绍 Functional Style。

如果采用 Hash Table 实现的话，那么复制时可能会遇到效率上的问题。我们可以用 Binary search Tree 的方式来存储。如果我们要在 depth d 插入一个节点，那么我们需要复制 d 个新结点，将通往 root 路径上的结点全都复制一份。

有介绍了 Tiger 语言的 Hash table 实现。

将 id string 和 symbol 一一对应。运用了辅助栈，用来记录每个操作。这个辅助栈在 Tiger Language 中的具体实现是靠着 Table 中的 top 和 binder 结构中的 prevtop 来实现的。所谓的 symbol 就是一个有着字符串和 next 指针的结构。所谓的 Binder 就是有着 key, value, next, prevtop 的结构。

接下来介绍了 tiger 语言的 symbol table 的具体实现。

tiger 语言的 symbol table 存在两种类型的命名空间，一个存储了 type，另一个则存储了 functions **和** variables。

接下来介绍了 Type-Checking expressions

Type-Checking 是根据 AST 进行判断的。

接下来进入了 Chapter 6，Activation Records。活动记录。

听起来类似于内存中栈的内容。RA 之类的。

## 4-10 第七周

首先介绍了 Frame pointer。
