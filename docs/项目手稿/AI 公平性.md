# AI 公平性

## 生成图片类型

对比 文心一言 与 stable diffusion online

### 性别

#### 医生

![](img/655e54815f693b2fe25045d7d3be20fc_MD5.png)

![](img/4093e557b41fd7f54adb834e12220251_MD5.png)

在 stable diffusion online 的网站上，输入“医生” 出现的结果千奇百怪。
![](img/56834cb295b0e4adb787ba206bdc6dd1_MD5.png)

在采用 docker 作为输入后，有正常的结果

![](img/6b559306ade2d0c75c6658e6b2b39e15_MD5.png)

在正常的结果中，全为男性

#### 老师

![](img/d640b57267757a366754963d79a8ea6f_MD5.png)

![](img/b9bc279b0c1ef8d45c9a96da717e2c70_MD5.png)

![](img/c55ccac5c50c40d969c066bbd999ddf6_MD5.png)

![](img/8b3277fef42b8740ddb63737dc6dd3ba_MD5.png)

![](img/6165defeb21f99fc6d43ec92a5ec2236_MD5.png)

### 政治倾向

![](img/2bbc0f6af2608d6d28de639bcf207bb3_MD5.png)

![](img/4596a07ea82884d77a2e07f0dc5e95fb_MD5.png)

![](img/0933bf6d24d501c9523c6d6ffdf7774f_MD5.png)

![](img/033ab0ce201fe1ce8925aca5106da3b1_MD5.png)

![](img/cf5c2f1ce17f849d4a3928e2410ee6b1_MD5.png)

## 结论

文心一言在处理某些提示词时不予答复或只能给出不相关的答复，那么这种情况可能会被认为是不公平的，因为这可能影响到用户的体验和信息获取。一方面，文心一言所使用的数据集可能存在偏见和不平衡，可能会导致其对于一些关键词的处理不足或者无法回答。这种情况下，需要对数据集进行评估和清洗，以确保数据的代表性和可信度。另一方面是人为的干预，如果文心一言是被人为设置了对于某些关键词的回答策略，那么这可能会导致不公平的结果。这种情况下，需要考虑更加公正的回答策略，确保系统 A 的公平性和可靠性。

stable diffusion 在处理中文提示词时不予答复或者只能给出不相关的答复，但在处理英文提示词时能够给出稳定的答复，这种情况可能会被认为是不公平的。stable diffusion 系统的行为表明，它倾向于处理英文提示词，而忽视了中文提示词。这种行为可能会被视为语言歧视的体现，即系统对某种语言存在偏见，从而导致了不公平的结果。同实也反映了 stable diffusion 中文数据集质量问题，这个系统在处理中文提示词时可能受到了数据集质量的影响。如果系统使用的中文数据集不足或存在不平衡的问题，可能会导致系统对中文提示词的处理不足或者不准确，从而导致了不公平的结果。
