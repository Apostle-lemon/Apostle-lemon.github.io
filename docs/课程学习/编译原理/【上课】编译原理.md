# 编译原理

## 基本信息

上课的教材是虎书龙书。覆盖的虎书内容章节是：1~11,13,14,18。

- 成绩构成  
10% 作业  
10% 小测  
15% 期中考试  
25% 项目 DDL:5.28  
40% 期末作业

## 2-27 第一周

### 1.1 Modules and Interfaces

编译过程可以被划分为多个阶段，如词法分析器，语法分析器之类。分成模块之后，模块可以做到复用，避免了重复造轮子等问题。

### 1.2 Tools and Software

正则表达式：词法分析  
上下文无关文法：语法分析

Lex：Lex 工具可以根据用户提供的声明式规范，生成对应的词法分析器代码。
Yac：可以生成语法分析器代码。

### 1.3 Data Structure

我们采用树形结构来表示 IR。

![](img/dcd866109b937aeb58b60f4ee0cd9319_MD5.png)

我们通过结构体来表达在 grammar 处于 left hand 的变量。这种结构体由两种成员变量组成。第一种类型是 kind，他是一种 enum 类型，代表了当前结构体具体的类型。例如一个 A_stm_ 类型的机构体，其可能是 CompoundStm, 也可能是 AssignStm。第二种类型是 u, 它是一种 union 类型，用来存储具体的数据。

![](img/6e1ad82ea8e779324fa5d27b54570452_MD5.png)

由于分配空间的需要，因此我们在程序中通常采用的是指向结构体的指针。

### 2.1 Lexical Tokens

lexical token，词法单元。词法分析器，输入的是字符串流，输出的是词法单元流。词法单元流中的每一个词法单元必须符合特定的形式。

为了方便构造一个词法分析器，我们通常采用将我们想要的 lexical tokens 表示为 regular expression 的形式，而后通过 NFA 和 DFA，最终转换成我们想要的 lexer。

### 2.2 Regular Expression

`“”` 用引号表示必须要完全相同才能进行匹配。
`[a-z]` 代表可以匹配 a-z 中任意一个。
`[a-zA-Z]` 代表可以匹配 a-z, A-Z 中任意一个。
`.` 可以匹配任何  
`+` 匹配 `+` 前边的内容一次或多次  
`?` 匹配 `?` 前边的内容零次或一次

两个匹配的规则：

- Longest match: 最长匹配规则是指从输入中可以匹配任何正则表达式的最长初始子串作为下一个 token。这意味着，在使用最长匹配规则时，程序会尝试将输入中最长的子串与正则表达式匹配，直到找到一个匹配为止。
- Rule priority: 规则优先级是指在特定的最长初始子串中，可以匹配的第一个正则表达式决定了它的 token 类型。这意味着，当程序找到一个最长子串时，它将首先尝试使用第一个正则表达式进行匹配，如果成功，它将将该子串标记为该正则表达式所代表的 token 类型。

### 2.3 Finite Automata

为了跟踪最长匹配规则，我们可以使用两个变量：Last-Final（最近遇到的终止状态的状态号）和 Input-Position-at-Last-Final（最近遇到的终止状态的输入位置）。每当进入一个终止状态时，词法分析器都会更新这些变量。

Last-Final 记录最近遇到的终止状态的状态号，即已经成功匹配了某个正则表达式的子串所在的状态。这个变量的更新可以在进入每个终止状态时进行。如果在接下来的匹配中发现更长的子串可以匹配其他正则表达式，则更新 Last-Final 的值。

Input-Position-at-Last-Final 记录了最近遇到的终止状态的输入位置。这个变量在 Last-Final 更新时也应该一同更新。因为在更新 Last-Final 之后，我们需要将当前输入位置设置为 Input-Position-at-Last-Final，以便继续匹配后面的子串。

使用这两个变量，我们可以跟踪最长匹配规则，并在遇到终止状态时更新匹配位置。这种方法可以在词法分析中实现最长匹配规则，提高程序的效率和准确性。

deadstate：如果词法分析器到达一个无输出转移的非终止状态，这个状态就被称为“死状态”。此时，我们需要使用变量来记录已匹配的 token 以及其结束位置。

### 2.4 Nondeterministic Finite Automata

主要注意的是将 NFA 转换为 DFA 的过程。

## 3-6 第二周

### 3.1 Context Free Grammar

解析器需要根据语法规则来判断一个输入的 token 流是否符合特定的语法规则。这里我们使用的语法规则就是 CFG。当然 CFG 并不能表示所有的语言，但是对于编程语言而言，采用 CFG 是完全够用了的。

- derivation

derivation 描述的是如何从一个 start symbol $S$ 最终演化成我们最后的 language。我们可以将 derivation 的过程用树表示，这个树就是一个 parse tree。如果一个 string 可以被表示为多个不同的 parse tree，我们认为这个 grammar 是存在 ambiguity 问题的，因此我们需要重写 grammar 以使其不再 ambiguous。

### 3.2 Predictive Parsing

parsing 可以分为两种大的方式，一种是 top-down parsing，另一种是 bottom-up parsing。在这个编译原理课中，我们着重讲了 top-down parsing 中的 predictive parsing，也即 ll(k) parsing。这里的 ll(k) 指的是, parsing from left to right，left most derivation，look ahead k tokens。

为了使用 predictive parsing，我们通常的做法是将每个非终结符的 nullable，FIRST，FOLLOW 给表示出来。通常的做法是不断遍历每个 derivation，直到与前一次相比，nullable,FIRST 和 FOLLOW 都没有变化。最终结果可以通过表格来清晰表示。

一但表示出来这三个后，我们可以绘制第二张表格，在这个表格中，行代表了每个非终结符，列代表了 look ahead 得到的 token，而表格中的内容则代表了可以采取的 derivation。如果在一个格子中出现了两个 derivation，我们认为这时候需要改写 grammar。

## 3-13 第三周

这周主要讲了 LR parsing，这种做法是自底向上的一种方法。

LR(0) 分析是一种自底向上的语法分析技术。具体来说，该技术的步骤如下：首先根据文法构建出对应的 NFA（也可以省略，直接构造对应的 DFA），然后创建出对应的 DFA。接着，根据 DFA，构建出语法分析表（parsing table），在 NFA 每一个状态下，读入不同的终结符或非终结符时，对应的 DFA 会进行相应的移进或规约操作，这些操作的规则被编码到语法分析表中。最后，利用该表进行语法分析，解析输入的字符串。需要注意的是，LR(0) 分析器可以处理大部分上下文无关文法，但是在处理某些文法时可能会出现移进 - 规约冲突或规约 - 规约冲突，需要使用其他的 LR 分析器进行处理。

## 3-20 第四周
